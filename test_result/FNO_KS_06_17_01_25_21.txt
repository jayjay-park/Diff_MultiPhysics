time_step: 0.25
lr: 0.001
weight_decay: 0.0005
num_epoch: 500
integration_time: 0
num_train: 1000
num_test: 3000
num_trans: 0
iters: 6000
threshold: 0.0
batch_size: 10
loss_type: JAC
reg_param: 0.9
c: 0.8
dim: 127
T: 1501
optim_name: AdamW
cotangent: rand
dyn_sys: KS
Model Size: 10.300296783447266
Loss Type: JAC
Cotangent: tensor([[[1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.]],

        ...,

        [[1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0')
Batch Size: 10
Training Loss: tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>)
Test Loss: tensor(0.0664, device='cuda:0', grad_fn=<AddBackward0>)
Relative Error: tensor(0.8073, device='cuda:0', grad_fn=<DivBackward0>)
Mean Diff: tensor(1.7858)
Var Diff: tensor(0.8761)
MSE diff: 0.005147034686160623
JAC diff: 0.12336418766062707
