time_step: 0.01
lr: 0.001
weight_decay: 0.0005
num_epoch: 2
num_train: 3000
num_test: 2000
num_trans: 2000
iters: 6000
threshold: 0.0
batch_size: 1000
loss_type: JAC
reg_param: 0.5
num_init: 5
c: 0.0
noise: 0.01
dim: 3
T: 201
optim_name: AdamW
cotangent: FIM
dyn_sys: Lorenz
Loss Type: JAC
Batch Size: 1000
Training Loss: tensor(0.9243, device='cuda:0', grad_fn=<AddBackward0>)
Test Loss: 456.6122283935547
Learned mean: tensor([ 0.0118, -0.0321,  0.0581], device='cuda:0', grad_fn=<MeanBackward1>)
True mean: tensor([-1.8647, -1.8609, 24.2482])
MSE diff: 0.8652885854244232
JAC diff: 0.8806764483451843
